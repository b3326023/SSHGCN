{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原始 SHINE 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dot, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as bk\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from prepare_data import Data\n",
    "import os\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# os.environ[\"path\"] += os.pathsep + 'c:/program files (x86)/graphviz2.38/bin'\n",
    "# saveDir = \"C:/Users/user/Google 雲端硬碟/NCKU_NETAI/SHINE/DGE/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、讀取資料，包含:\n",
    "1. Sentiment Graph\n",
    "2. Social Relation Graph\n",
    "3. Profile Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 1\n",
    "data = Data('data/sentiment.csv',\n",
    "            'data/social_relation.csv',\n",
    "            'data/celebrity_profile.csv',\n",
    "            'data/ordinary_user_profile.csv',\n",
    "            train_ratio,\n",
    "           random_state=20) # random_state 設0為SHINE原始碼所用之切割，效果會最好，acc約有 80% 左右。\n",
    "\n",
    "X1_s_train, X2_s_train, y_train, X1_s_test, X2_s_test, y_test, _ = data.get_sentiment_data()\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "X1_r_train, X2_r_train, X1_r_test, X2_r_test, adj_matrix_r = data.get_relation_data()\n",
    "X1_p_train, X2_p_train, X1_p_test, X2_p_test, o_profile_one_hot, c_profile_one_hot = data.get_profile_data()\n",
    "\n",
    "input_dim_all_user = X1_s_train.shape[1]\n",
    "input_dim_op = X1_p_train.shape[1]\n",
    "input_dim_cp = X2_p_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 二、建構模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義幾個 Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put more weight on non-zero terms\n",
    "alpha = 10\n",
    "def reconstruction_loss(y_true, y_pred):\n",
    "    sqr = bk.square(y_pred - y_true)\n",
    "    weight = bk.abs(y_true) * (alpha - 1) + 1\n",
    "    return bk.sum(sqr * weight, axis=-1)\n",
    "\n",
    "def proximity_loss(y_true, y_pred):\n",
    "    return bk.sum(-y_pred * y_true, axis=-1)\n",
    "\n",
    "def proximity_loss_paper(y_true, y_pred):\n",
    "      return  bk.sum(bk.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 5\n",
    "batch_size = 512\n",
    "EMBEDDING_DIM = 64\n",
    "l2_weight = 0\n",
    "lambda_sen = 1\n",
    "lambda_soc = 1\n",
    "lambda_pro = 1\n",
    "lambda_output = 30\n",
    "sen_act = 'tanh'\n",
    "soc_act = 'sigmoid'\n",
    "pro_act = 'sigmoid'\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "recon_loss = reconstruction_loss\n",
    "proxi_loss = proximity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_all_user = X1_s_train.shape[1]\n",
    "input_dim_op = X1_p_train.shape[1]\n",
    "input_dim_cp = X2_p_train.shape[1]\n",
    "\n",
    "########## Sentiment graph autoencoder ##########\n",
    "# Input layer\n",
    "sen_holder_input = Input(shape=(input_dim_all_user,))\n",
    "sen_target_input = Input(shape=(input_dim_all_user,))\n",
    "\n",
    "# encoder\n",
    "sen_encoder = Dense(EMBEDDING_DIM, activation=sen_act, kernel_regularizer=l2(l2_weight))\n",
    "sen_holder_emb = sen_encoder(sen_holder_input)\n",
    "sen_target_emb = sen_encoder(sen_target_input)\n",
    "\n",
    "# decoder\n",
    "sen_decoder = Dense(input_dim_all_user, activation=sen_act, kernel_regularizer=l2(l2_weight))\n",
    "sen_recon_holder = sen_decoder(sen_holder_emb)\n",
    "sen_recon_target = sen_decoder(sen_target_emb)\n",
    "\n",
    "# dot product of two users\n",
    "sen_proximity = Dot(axes=-1, normalize=True)([sen_holder_emb, sen_target_emb])\n",
    "\n",
    "\n",
    "########## Social relation graph autoencoder ##########\n",
    "# Input layer\n",
    "soc_holder_input = Input(shape=(input_dim_all_user,))\n",
    "soc_target_input = Input(shape=(input_dim_all_user,))\n",
    "\n",
    "# encoder\n",
    "soc_encoder = Dense(EMBEDDING_DIM, activation=soc_act, kernel_regularizer=l2(l2_weight))\n",
    "soc_holder_emb = soc_encoder(soc_holder_input)\n",
    "soc_target_emb = soc_encoder(soc_target_input)\n",
    "\n",
    "# decoder\n",
    "soc_decoder = Dense(input_dim_all_user, activation=soc_act, kernel_regularizer=l2(l2_weight))\n",
    "soc_recon_holder = soc_decoder(soc_holder_emb)\n",
    "soc_recon_target = soc_decoder(soc_target_emb)\n",
    "\n",
    "# dot product of two users\n",
    "soc_proximity = Dot(axes=-1, normalize=True)([soc_holder_emb, soc_target_emb])\n",
    "\n",
    "\n",
    "########## Profile graph autoencoder ##########\n",
    "# o: ordinary people, c: celebrity\n",
    "# Input layer\n",
    "pro_o_input = Input(shape=(input_dim_op,))\n",
    "pro_c_input = Input(shape=(input_dim_cp,))\n",
    "\n",
    "# encoder\n",
    "pro_o_encoder = Dense(EMBEDDING_DIM, activation=pro_act, kernel_regularizer=l2(l2_weight))\n",
    "pro_c_encoder = Dense(EMBEDDING_DIM, activation=pro_act, kernel_regularizer=l2(l2_weight))\n",
    "pro_o_emb = pro_o_encoder(pro_o_input)\n",
    "pro_c_emb = pro_c_encoder(pro_c_input)\n",
    "\n",
    "# decoder\n",
    "pro_o_decoder = Dense(input_dim_op, activation=pro_act, kernel_regularizer=l2(l2_weight))\n",
    "pro_c_decoder = Dense(input_dim_cp, activation=pro_act, kernel_regularizer=l2(l2_weight))\n",
    "pro_recon_o = pro_o_decoder(pro_o_emb)\n",
    "pro_recon_c = pro_c_decoder(pro_c_emb)\n",
    "\n",
    "# dot product of two users\n",
    "pro_proximity = Dot(axes=-1, normalize=True)([pro_o_emb, pro_c_emb])\n",
    "\n",
    "\n",
    "########## Aggregation layer ##########\n",
    "# 最終預測情感值\n",
    "proximity = Add()([sen_proximity, soc_proximity, pro_proximity])\n",
    "\n",
    "# 訓練用模型\n",
    "model = Model(inputs=[sen_holder_input, sen_target_input, soc_holder_input, soc_target_input, pro_o_input, pro_c_input],\n",
    "              outputs=[sen_recon_holder, sen_recon_target, soc_recon_holder, soc_recon_target, pro_recon_o, pro_recon_c, proximity])\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=[recon_loss, recon_loss, recon_loss,\n",
    "                    recon_loss, recon_loss, recon_loss, proxi_loss],\n",
    "              loss_weights=[lambda_sen, lambda_sen, lambda_soc, lambda_soc, lambda_pro, lambda_pro, lambda_output])\n",
    "\n",
    "# 預測用模型\n",
    "predict_model = Model(inputs=[sen_holder_input, sen_target_input, soc_holder_input, soc_target_input, pro_o_input, pro_c_input],\n",
    "                      outputs=proximity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "103/103 [==============================] - 41s 401ms/step - loss: 1606.6571 - dense_1_loss: 112.0320 - dense_1_1_loss: 345.6243 - dense_3_loss: 382.4989 - dense_3_1_loss: 805.9487 - dense_6_loss: 3.9288 - dense_7_loss: 15.7391 - add_loss: -1.9705 - val_loss: 1121.9728 - val_dense_1_loss: 89.1009 - val_dense_1_1_loss: 259.8479 - val_dense_3_loss: 185.0192 - val_dense_3_1_loss: 581.8954 - val_dense_6_loss: 1.4808 - val_dense_7_loss: 7.2567 - val_add_loss: -0.0876\n",
      "Epoch 2/5\n",
      "103/103 [==============================] - 43s 413ms/step - loss: 900.4269 - dense_1_loss: 102.8346 - dense_1_1_loss: 260.9960 - dense_3_loss: 150.4820 - dense_3_1_loss: 440.5418 - dense_6_loss: 0.9596 - dense_7_loss: 4.6772 - add_loss: -2.0021 - val_loss: 874.4839 - val_dense_1_loss: 89.8262 - val_dense_1_1_loss: 263.5097 - val_dense_3_loss: 114.2219 - val_dense_3_1_loss: 405.7770 - val_dense_6_loss: 0.6047 - val_dense_7_loss: 3.2333 - val_add_loss: -0.0896\n",
      "Epoch 3/5\n",
      "103/103 [==============================] - 39s 374ms/step - loss: 785.7092 - dense_1_loss: 103.0592 - dense_1_1_loss: 260.8984 - dense_3_loss: 123.2835 - dense_3_1_loss: 355.8315 - dense_6_loss: 0.4693 - dense_7_loss: 2.5332 - add_loss: -2.0122 - val_loss: 802.1855 - val_dense_1_loss: 90.0027 - val_dense_1_1_loss: 261.1097 - val_dense_3_loss: 105.6103 - val_dense_3_1_loss: 345.6452 - val_dense_6_loss: 0.3319 - val_dense_7_loss: 2.1320 - val_add_loss: -0.0882\n",
      "Epoch 4/5\n",
      "103/103 [==============================] - 36s 348ms/step - loss: 724.8773 - dense_1_loss: 102.8966 - dense_1_1_loss: 262.4225 - dense_3_loss: 114.9201 - dense_3_1_loss: 303.0392 - dense_6_loss: 0.2983 - dense_7_loss: 1.7937 - add_loss: -2.0164 - val_loss: 745.4366 - val_dense_1_loss: 89.9630 - val_dense_1_1_loss: 261.3749 - val_dense_3_loss: 99.2277 - val_dense_3_1_loss: 295.6491 - val_dense_6_loss: 0.2308 - val_dense_7_loss: 1.5894 - val_add_loss: -0.0866\n",
      "Epoch 5/5\n",
      "103/103 [==============================] - 36s 345ms/step - loss: 675.8613 - dense_1_loss: 103.2742 - dense_1_1_loss: 262.5377 - dense_3_loss: 108.7342 - dense_3_1_loss: 260.3146 - dense_6_loss: 0.2314 - dense_7_loss: 1.3988 - add_loss: -2.0210 - val_loss: 704.4499 - val_dense_1_loss: 89.9245 - val_dense_1_1_loss: 267.7521 - val_dense_3_loss: 94.8800 - val_dense_3_1_loss: 252.9195 - val_dense_6_loss: 0.1842 - val_dense_7_loss: 1.2825 - val_add_loss: -0.0831\n",
      "Time:  276.59653282538056\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "h = model.fit(x=[X1_s_train, X2_s_train, X1_r_train, X2_r_train, X1_p_train, X2_p_train],\n",
    "              y=[X1_s_train, X2_s_train, X1_r_train, X2_r_train, X1_p_train, X2_p_train, y_train],\n",
    "              epochs=epoch_size,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=([X1_s_test, X2_s_test, X1_r_test, X2_r_test, X1_p_test, X2_p_test],\n",
    "                               [X1_s_test, X2_s_test, X1_r_test, X2_r_test, X1_p_test, X2_p_test, y_test]),\n",
    "             verbose=1)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製訓練誤差與驗證誤差圖，此處只看最終預測值的誤差而不看 Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['add_loss'], label='train_loss')\n",
    "plt.plot(h.history['val_add_loss'], label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 效果評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc, F1, AUC:\n",
      "Train\n",
      "0.5940079486395597\n",
      "0.71071477195371\n",
      "0.9768670286794083\n",
      "\n",
      "Test\n",
      "0.6266556291390728\n",
      "0.6266556291390728\n",
      "0.6732339042147275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def result(X, Y, mode=''):\n",
    "    # 模型預測值\n",
    "    y_predict_raw = predict_model.predict(X).flatten()\n",
    "    y_predict = y_predict_raw.copy()\n",
    "    \n",
    "    # 計算中位數當作二分的門檻值\n",
    "    y_threshold = np.median(y_predict_raw)\n",
    "    y_predict[y_predict_raw < y_threshold] = -1\n",
    "    y_predict[y_predict_raw >= y_threshold] = 1\n",
    "    \n",
    "    # 用 Ground Truth 計算各種 Metrics\n",
    "    accuracy = accuracy_score(Y, y_predict)\n",
    "    f1 = f1_score(Y, y_predict, average='binary')\n",
    "    AUC = roc_auc_score(Y, y_predict_raw)\n",
    "    print(mode)\n",
    "    print(accuracy)\n",
    "    print(f1)\n",
    "    print(AUC)\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Acc, F1, AUC:\")\n",
    "result(X=[X1_s_train, X2_s_train, X1_r_train, X2_r_train, X1_p_train, X2_p_train], Y=y_train, mode='Train')\n",
    "result(X=[X1_s_test, X2_s_test, X1_r_test, X2_r_test, X1_p_test, X2_p_test], Y=y_test, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 25628)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 25628)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 25628)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25628)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 37)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 108)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           1640256     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           1640256     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           2432        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           6976        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25628)        1665820     dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 25628)        1665820     dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 37)           2405        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 108)          7020        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           dot[0][0]                        \n",
      "                                                                 dot_1[0][0]                      \n",
      "                                                                 dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 6,630,985\n",
      "Trainable params: 6,630,985\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
